# Speech_Emotion_Recognition
This Speech Emotion Recognition project uses the TESS dataset to classify emotions (angry, happy, sad, etc.) from audio. It extracts features like MFCC, chroma, and spectral metrics using librosa, trains a Random Forest model, and offers real-time emotion prediction from microphone input.
